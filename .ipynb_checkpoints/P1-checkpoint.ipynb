{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#resets all the variables: needs the confirmation of the deletion \n",
    "%reset \n",
    "#importing some useful packages\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    #Applies the Grayscale transform\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    #Applies the Canny transform\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    #Applies a Gaussian Noise kernel\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    #Masking: Only keeps the region of the image defined by the polygon    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)     \n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def unifyLines(slope, intercept, imshape, Yvertice):\n",
    "    #This finsction replaces 'draw_lines' function\n",
    "    # It defines the final lines using the average of all lines' slope and intercept\n",
    "    # and outputs the coordination of lines two points\n",
    "    x1LR, x2LR = ([imshape[0],Yvertice+40]-intercept)/slope\n",
    "    return [int(x1LR), imshape[0], int(x2LR), Yvertice+40]\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    #Returns an image with hough lines drawn\n",
    "    #`img` should be the output of a Canny transform.\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing\n",
    "Bellow the code is run on different images to find the lane lines in different cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files  = os.listdir(\"test_images/\")\n",
    "images = [image for image in files if (image.endswith(\".jpg\"))]\n",
    "\n",
    "for image in images:\n",
    "    #reading in an image\n",
    "    img = cv2.imread('test_images/%s'%image)\n",
    "    #preparing the image for line search\n",
    "    gray = grayscale(img)\n",
    "    guss = gaussian_blur(gray, 5)\n",
    "    edges = canny(guss, 50, 150)\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255 \n",
    "    imshape = img.shape\n",
    "    ##defining the region of interest\n",
    "    Yvertice = 290\n",
    "    vertices = np.array([[(0,imshape[0]),(450, Yvertice), (490, Yvertice), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    #cv2.polylines(img, [vertices], True, (0,0,225), 3)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)   \n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "    \n",
    "    ##detecting the lines\n",
    "    min_line_length=40\n",
    "    max_line_gap=20\n",
    "    threshold=15\n",
    "    theta=np.pi/180\n",
    "    rho=1\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "\n",
    "    ##Split lines into right- and left-line groups \n",
    "    lineNum = 0\n",
    "    leftSlope= np.array([])\n",
    "    leftInterc= np.array([])\n",
    "    rightSlope= np.array([])\n",
    "    rightInterc= np.array([])\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            tanAlpha = (y2-y1)/(x2-x1)\n",
    "            if np.tan(-np.pi/8) < tanAlpha < np.tan(np.pi/8):\n",
    "                #If a line -pi/8<angle<pi/8, delete it from the set\n",
    "                #such a lane line most probably doesn't exist\n",
    "                np.delete(lines, lineNum)\n",
    "            else: \n",
    "                if tanAlpha <0:\n",
    "                    leftFit    = np.polyfit([x1,x2], [y1, y2], 1)\n",
    "                    leftSlope  = np.concatenate((leftSlope ,[leftFit[0]]))\n",
    "                    leftInterc = np.concatenate((leftInterc,[leftFit[1]]))\n",
    "                else:\n",
    "                    rightFit    = np.polyfit([x1,x2], [y1, y2], 1)\n",
    "                    rightSlope  = np.concatenate((rightSlope ,[rightFit[0]]))\n",
    "                    rightInterc = np.concatenate((rightInterc,[rightFit[1]]))\n",
    "                    \n",
    "        lineNum += 1\n",
    "    ##Defining the final lines using the average of all lines' slope and intercept\n",
    "    ##and outputting the coordination of their two points\n",
    "    [x1L, y1L, x2L, y2L] = unifyLines(leftSlope.mean(),  leftInterc.mean(),  imshape, Yvertice)    \n",
    "    [x1R, y1R, x2R, y2R] = unifyLines(rightSlope.mean(), rightInterc.mean(), imshape, Yvertice)                                                 \n",
    "    \n",
    "    #Draw the final lines on a blank image\n",
    "    line_image = np.copy(img)*0\n",
    "    cv2.line(line_image,(x1L,y1L),(x2L,y2L),(255,0,255),12)  \n",
    "    cv2.line(line_image,(x1R,y1R),(x2R,y2R),(255,0,255),12) \n",
    "        \n",
    "    color_edges = np.dstack((edges, edges, edges))\n",
    "    # Draw the lines on the edge image\n",
    "    lines_img = cv2.addWeighted(img, 1.0, line_image, 0.2, 0) \n",
    "\n",
    "    try:\n",
    "        os.stat(\"test_images_output\")\n",
    "    except:\n",
    "        os.mkdir(\"test_images_output\")\n",
    "    \n",
    "    cv2.imwrite(\"test_images_output/%s\"%image, lines_img)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video processing\n",
    "\n",
    "`process_image` containes the similar process as detecting lines on the image, but for videos. Some more code is added to keep the consistancy of line existance in case a line could not be found in an image frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_image(img):\n",
    "    #The output sould be a colored image (3-channel)\n",
    "    global leftLineParam, rightLineParam\n",
    "    #preparing the image for line search\n",
    "    gray = grayscale(img)\n",
    "    guss = gaussian_blur(gray, 5)\n",
    "    edges = canny(guss, 50, 150)\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255 \n",
    "    imshape = img.shape\n",
    "\n",
    "    ##defining the region of interest\n",
    "    Yvertice = int(imshape[0]/2 +15)\n",
    "    Xvertice = int(imshape[1]/2)\n",
    "    vertices = np.array([[(0,imshape[0]),(Xvertice-15, Yvertice), (Xvertice+15, Yvertice), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    #cv2.polylines(img, [vertices], True, (0,0,225), 3)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "    ##detecting the lines\n",
    "    min_line_length=40\n",
    "    max_line_gap=20\n",
    "    threshold=15\n",
    "    theta=np.pi/180\n",
    "    rho=1\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "\n",
    "    ##Split lines into right- and left-line groups \n",
    "    lineNum = 0\n",
    "    leftSlope = np.array([])\n",
    "    leftInterc = np.array([])\n",
    "    rightSlope = np.array([])\n",
    "    rightInterc = np.array([])\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            tanAlpha = (y2-y1)/(x2-x1)\n",
    "            if np.tan(-np.pi/8) < tanAlpha < np.tan(np.pi/8): \n",
    "                #If a line -pi/8<angle<pi/8, delete it from the set\n",
    "                #such a lane line most probably doesn't exist\n",
    "                np.delete(lines, lineNum)\n",
    "            else: \n",
    "                if tanAlpha >0:\n",
    "                    leftFit    = np.polyfit([x1,x2], [y1, y2], 1)\n",
    "                    leftSlope  = np.concatenate((leftSlope ,[leftFit[0]]))\n",
    "                    leftInterc = np.concatenate((leftInterc,[leftFit[1]]))\n",
    "                else:\n",
    "                    rightFit    = np.polyfit([x1,x2], [y1, y2], 1)\n",
    "                    rightSlope  = np.concatenate((rightSlope ,[rightFit[0]]))\n",
    "                    rightInterc = np.concatenate((rightInterc,[rightFit[1]]))\n",
    "        lineNum += 1\n",
    "    \n",
    "    if leftSlope.size == 0:\n",
    "        #If no line could be detected in either side, use the line from previous image frame\n",
    "        [x1L, y1L, x2L, y2L] = leftLineParam\n",
    "    else:\n",
    "        #Defining the final lines by the coordination of their two points\n",
    "        [x1L, y1L, x2L, y2L] = unifyLines(leftSlope.mean(), leftInterc.mean(), imshape, Yvertice) \n",
    "        leftLineParam = [x1L, y1L, x2L, y2L]\n",
    "\n",
    "    if rightSlope.size == 0:\n",
    "        [x1R, y1R, x2R, y2R] = rightLineParam\n",
    "    else:\n",
    "        [x1R, y1R, x2R, y2R] = unifyLines(rightSlope.mean(), rightInterc.mean(), imshape, Yvertice) \n",
    "        rightLineParam = [x1R, y1R, x2R, y2R]\n",
    "\n",
    "    #Draw the final lines on a blank image\n",
    "    line_image = np.copy(img)*0\n",
    "    cv2.line(line_image,(x1L,y1L),(x2L,y2L),(255,0,255),12)  \n",
    "    cv2.line(line_image,(x1R,y1R),(x2R,y2R),(255,0,255),12) \n",
    "        \n",
    "    color_edges = np.dstack((edges, edges, edges))\n",
    "    # Draw the lines on the colored image\n",
    "    lines_edges = cv2.addWeighted(img, 0.8, line_image, 1, 0) \n",
    "\n",
    "    return lines_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "Bellow are three test on three different videos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:05<00:00, 37.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 3.36 s, sys: 529 ms, total: 3.89 s\n",
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#If the output directory doesn't exist, create one\n",
    "try:\n",
    "    os.stat(\"test_videos_output\")\n",
    "except:\n",
    "    os.mkdir(\"test_videos_output\")\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #This function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:16<00:00, 38.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 10.4 s, sys: 1.82 s, total: 12.3 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:13<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 7.17 s, sys: 1.82 s, total: 8.99 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
